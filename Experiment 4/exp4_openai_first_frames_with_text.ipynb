{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S52uxO9pVmo2"
      },
      "source": [
        "## OpenAI Vision 4 Image-to-Text Descriptions of First Frames (focusing on text, i.e. color, size, placement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upGEHAqfVpDi"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install openai\n",
        "!pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt199oHjVmo6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image, Audio\n",
        "\n",
        "import cv2\n",
        "import base64\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG_kWFvsq1uy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYuXVRrOvpdh"
      },
      "source": [
        "## Loop through Training Set, create OpenAI descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEMt5udrg0D8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "from openai import BadRequestError, RateLimitError\n",
        "\n",
        "# Function to convert image to base64\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Directory containing images\n",
        "image_dir = \"/content/drive/My Drive/236/train_first_frames/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHnpuW-YgzeF"
      },
      "outputs": [],
      "source": [
        "# Load train.csv into a DataFrame\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/236/train.csv\")\n",
        "\n",
        "print (len(train_df))\n",
        "train_df[\"OpenAICaption\"] = np.nan\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qL2cGMSzxxi"
      },
      "outputs": [],
      "source": [
        "# Load test.csv, when testing\n",
        "image_dir = \"/content/drive/My Drive/236/test_first_frames/\"\n",
        "test_df = pd.read_csv(\"/content/drive/My Drive/236/test.csv\")\n",
        "test_df[\"OpenAICaption\"] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz78bg27KNeH"
      },
      "source": [
        "### Batch calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIg0TQlKbqAf"
      },
      "outputs": [],
      "source": [
        "# TRAIN SET\n",
        "\n",
        "id_set = set(train_df['Id'].values)\n",
        "progress = 0\n",
        "batch_size = 5\n",
        "batch = []\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        identifier = filename.split(\"_\", 1)[1][:-4]  # Removes the \".jpg\" at the end\n",
        "\n",
        "        if identifier in id_set and not pd.isna(train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'].iloc[0]):\n",
        "            continue\n",
        "\n",
        "        base64_image = encode_image(image_dir + filename)\n",
        "\n",
        "        # Append to the batch\n",
        "        batch.append({\n",
        "            \"image\": base64_image,\n",
        "            \"identifier\": identifier\n",
        "        })\n",
        "\n",
        "\n",
        "        if len(batch) == batch_size:\n",
        "            message = {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Each image is the first frame of a YouTube video. Generate an around 30-word description for each image that would be useful for creating a good thumbnail image, including subject matter, composition, style and descriptions of how any text should look, including text size, color, and placement. List each description on a new line without numbering. If you are unable to provide a description, return 'no description available'\",\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            for item in batch:\n",
        "                batch_image = {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{item['image']}\"\n",
        "                            }\n",
        "                        }\n",
        "                message[\"content\"].append(batch_image)\n",
        "\n",
        "            params = {\n",
        "                \"model\": \"gpt-4-vision-preview\",\n",
        "                \"messages\": [message],\n",
        "                \"max_tokens\": 4000,\n",
        "            }\n",
        "\n",
        "            try:\n",
        "              result = client.chat.completions.create(**params)\n",
        "              result_list = result.choices[0].message.content.split(\"\\n\")\n",
        "\n",
        "              for i in range(batch_size):\n",
        "                description = result_list[i]\n",
        "                identifier = batch[i][\"identifier\"]\n",
        "                train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'] = description\n",
        "                print(f\"{identifier}: {description}\")\n",
        "\n",
        "              progress += batch_size\n",
        "              print(progress)\n",
        "\n",
        "              train_df.to_csv(\"/content/drive/My Drive/train_images_exp4_openai.csv\", index=False)\n",
        "\n",
        "            except (RateLimitError) as e:\n",
        "                print(f\"Error: {e}, waiting...\")\n",
        "                time.sleep(90)\n",
        "            except (BadRequestError) as e:\n",
        "                print(f\"Error: {e}, skipping batch.\")\n",
        "                batch = []\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error: {e}, skipping batch.\")\n",
        "                batch = []\n",
        "                continue\n",
        "\n",
        "            # Reset the batch\n",
        "            batch = []\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "train_df.to_csv(\"/content/drive/My Drive/train_images_exp4_openai.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYSOxSek0BhK"
      },
      "outputs": [],
      "source": [
        "#  TEST SET\n",
        "\n",
        "id_set = set(test_df['Id'].values)\n",
        "progress = 0\n",
        "batch_size = 1\n",
        "batch = []\n",
        "num = 0\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    num += 1\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        identifier = filename.split(\"_\", 1)[1][:-4]  # Removes the \".jpg\" at the end\n",
        "\n",
        "        if identifier in id_set and not pd.isna(test_df.loc[test_df['Id'] == identifier, 'OpenAICaption'].iloc[0]):\n",
        "            num += 1\n",
        "            continue\n",
        "\n",
        "        base64_image = encode_image(image_dir + filename)\n",
        "\n",
        "        # Append to the batch\n",
        "        batch.append({\n",
        "            \"image\": base64_image,\n",
        "            \"identifier\": identifier\n",
        "        })\n",
        "\n",
        "\n",
        "        if len(batch) == batch_size:\n",
        "            message = {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Each image is the first frame of a YouTube video. Generate an around 30-word description for each image that would be useful for creating a good thumbnail image, including subject matter, composition, style and descriptions of how any text should look, including text size, color, and placement. List each description on a new line without numbering. If you are unable to provide a description, return 'no description available'\",\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            for item in batch:\n",
        "                batch_image = {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{item['image']}\"\n",
        "                            }\n",
        "                        }\n",
        "                message[\"content\"].append(batch_image)\n",
        "\n",
        "            params = {\n",
        "                \"model\": \"gpt-4-vision-preview\",\n",
        "                \"messages\": [message],\n",
        "                \"max_tokens\": 4000\n",
        "            }\n",
        "\n",
        "            try:\n",
        "              result = client.chat.completions.create(**params)\n",
        "              result_list = result.choices[0].message.content.split(\"\\n\")\n",
        "\n",
        "              for i in range(batch_size):\n",
        "                description = result_list[i]\n",
        "                identifier = batch[i][\"identifier\"]\n",
        "                test_df.loc[test_df['Id'] == identifier, 'OpenAICaption'] = description\n",
        "                print(f\"{identifier}: {description}\")\n",
        "\n",
        "              progress += batch_size\n",
        "              print(progress)\n",
        "\n",
        "              test_df.to_csv(\"/content/drive/My Drive/236/test_images_exp4_openai.csv\", index=False)\n",
        "              time.sleep(30)\n",
        "\n",
        "            except (RateLimitError) as e:\n",
        "                print(f\"Error: {e}, waiting...\")\n",
        "                time.sleep(90)\n",
        "            except (BadRequestError) as e:\n",
        "                print(f\"Error: {e}, skipping batch.\")\n",
        "                batch = []\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error: {e}, skipping batch.\")\n",
        "                batch = []\n",
        "                continue\n",
        "\n",
        "            # Reset the batch\n",
        "            batch = []\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "test_df.to_csv(\"/content/drive/My Drive/236/test_images_exp4_openai.csv\", index=False)\n",
        "print (num)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGXlh7GKJga"
      },
      "source": [
        "### Individual calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYinHLhtpZ32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "import pandas as pd\n",
        "import time\n",
        "from openai import BadRequestError, RateLimitError\n",
        "\n",
        "# Function to convert image to base64\n",
        "def image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "# Directory containing images\n",
        "image_dir = \"/content/drive/My Drive/236/train_first_frames\"\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/train_images_exp2_openai.csv\")\n",
        "\n",
        "id_set = set(train_df['Id'].values)\n",
        "progress = 0\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        # Extract the identifier from the filename\n",
        "        identifier = filename.split(\"_\", 1)[1][:-4]  # Removes the \".jpg\" at the\n",
        "\n",
        "        if identifier in id_set and not pd.isna(train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'].iloc[0]):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        base64_image = image_to_base64(image_path)\n",
        "\n",
        "        # Create the prompt message\n",
        "        prompt_message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                \"This is the first frame from a YouTube video. Generate a less than 20 word description of the video that would be useful for creating a good thumbnail image.\",\n",
        "                {\"image\": base64_image, \"resize\": 256}\n",
        "            ],\n",
        "        }\n",
        "\n",
        "        # Prepare parameters for the API call\n",
        "        params = {\n",
        "            \"model\": \"gpt-4-vision-preview\",\n",
        "            \"messages\": [prompt_message],\n",
        "            \"max_tokens\": 200\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            result = client.chat.completions.create(**params)\n",
        "            description = result.choices[0].message.content\n",
        "\n",
        "            if \"I'm sorry\" in description or \"I cannot\" in description:\n",
        "                train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'] = \"no description available\"\n",
        "            else:\n",
        "                train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'] = description\n",
        "\n",
        "            progress += 1\n",
        "            print(progress)\n",
        "\n",
        "            if progress % 10 == 0:  # Save every 10 iterations\n",
        "                train_df.to_csv(\"/content/drive/My Drive/train_images_exp2_openai.csv\", index=False)\n",
        "\n",
        "            time.sleep(30)\n",
        "\n",
        "        except (RateLimitError) as e:\n",
        "            print(f\"Error: {e}, waiting...\")\n",
        "            time.sleep(30)\n",
        "        except (BadRequestError) as e:\n",
        "            print(f\"Error: {e}, skipping image.\")\n",
        "            train_df.loc[train_df['Id'] == identifier, 'OpenAICaption'] = \"no description available\"\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e}, skipping image.\")\n",
        "            continue\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "train_df.to_csv(\"/content/drive/My Drive/train_images_exp2_openai.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO4iO66ZKSID"
      },
      "source": [
        "### See Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNFu843SEJ7R"
      },
      "outputs": [],
      "source": [
        "# Save the updated DataFrame back to CSV\n",
        "train_df.to_csv(\"/content/drive/My Drive/train_images_exp2_openai.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul0Woovb3Vsf"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "for index, row in train_df.iterrows():\n",
        "    if pd.notna(row['OpenAICaption']) and row['OpenAICaption'] != '':\n",
        "        print(f\"Row {index}: {row['OpenAICaption']}\")\n",
        "        num += 1\n",
        "print (len(train_df))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
